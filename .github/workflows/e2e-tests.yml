name: E2E Tests

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main, develop]
  workflow_dispatch:

# Cancel in-progress runs when a new workflow with the same group name is triggered
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    timeout-minutes: 60
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        browser: [chromium, firefox, webkit]
        shardIndex: [1, 2]
        shardTotal: [2]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright Browsers
        run: npx playwright install --with-deps ${{ matrix.browser }}

      - name: Run E2E tests
        run: npx playwright test --project=${{ matrix.browser }} --shard=${{ matrix.shardIndex }}/${{ matrix.shardTotal }}
        env:
          CI: true

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.browser }}-${{ matrix.shardIndex }}
          path: test-results/
          retention-days: 30

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-${{ matrix.browser }}-${{ matrix.shardIndex }}
          path: playwright-report/
          retention-days: 30

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-artifacts-${{ matrix.browser }}-${{ matrix.shardIndex }}
          path: |
            test-results/**/*.png
            test-results/**/*.webm
            test-results/**/*.zip
          retention-days: 30

  # Merge and report job
  report:
    if: always()
    needs: [test]
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: read
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-artifacts

      - name: Merge test results
        run: |
          mkdir -p merged-results
          find all-artifacts -name "results.json" -exec cp {} merged-results/ \;
          ls -la merged-results/

      - name: Generate test summary
        id: test-summary
        run: |
          # Count test results
          TOTAL_TESTS=0
          PASSED_TESTS=0
          FAILED_TESTS=0
          SKIPPED_TESTS=0
          
          for file in merged-results/*.json; do
            if [ -f "$file" ]; then
              # Parse JSON to count tests (simplified)
              TOTAL=$((TOTAL + $(grep -o '"status"' "$file" | wc -l)))
              PASSED=$((PASSED + $(grep -o '"status":"passed"' "$file" | wc -l)))
              FAILED=$((FAILED + $(grep -o '"status":"failed"' "$file" | wc -l)))
              SKIPPED=$((SKIPPED + $(grep -o '"status":"skipped"' "$file" | wc -l)))
            fi
          done
          
          echo "total=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "passed=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "skipped=$SKIPPED_TESTS" >> $GITHUB_OUTPUT

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Find failed tests and screenshots
            let failedTests = [];
            let hasScreenshots = false;
            
            try {
              const artifactsPath = 'all-artifacts';
              const dirs = fs.readdirSync(artifactsPath);
              
              for (const dir of dirs) {
                const resultsPath = path.join(artifactsPath, dir);
                if (fs.existsSync(resultsPath)) {
                  // Check for diff screenshots
                  const files = fs.readdirSync(resultsPath, { recursive: true });
                  const diffFiles = files.filter(f => f.includes('-diff.png'));
                  if (diffFiles.length > 0) {
                    hasScreenshots = true;
                    failedTests.push(`${dir}: ${diffFiles.length} visual differences`);
                  }
                }
              }
            } catch (error) {
              console.log('Error reading artifacts:', error);
            }
            
            const testUrl = `https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}`;
            const status = '${{ needs.test.result }}' === 'success' ? 'âœ…' : 'âŒ';
            
            let comment = `## ${status} E2E Test Results\n\n`;
            comment += `**Workflow:** [View Details](${testUrl})\n\n`;
            comment += `### Summary\n`;
            comment += `- **Status:** ${{ needs.test.result }}\n`;
            comment += `- **Browsers:** chromium, firefox, webkit\n`;
            comment += `- **Shards:** 2 per browser\n\n`;
            
            if (failedTests.length > 0) {
              comment += `### âš ï¸ Visual Regression Failures\n\n`;
              comment += failedTests.map(t => `- ${t}`).join('\n');
              comment += `\n\nðŸ“¸ [Download screenshot artifacts](${testUrl}) to review differences.\n\n`;
            }
            
            if ('${{ needs.test.result }}' === 'failure') {
              comment += `### ðŸ” Next Steps\n`;
              comment += `1. Check the [workflow run](${testUrl}) for detailed errors\n`;
              comment += `2. Download test artifacts to see screenshots/videos\n`;
              comment += `3. Review failed test logs in the Actions tab\n`;
              if (hasScreenshots) {
                comment += `4. If visual changes are intentional, update baselines with \`npm run test:e2e -- --update-snapshots\`\n`;
              }
            }
            
            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('E2E Test Results')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
